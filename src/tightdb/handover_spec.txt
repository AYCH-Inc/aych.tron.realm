Spec: handover of query results between threads
===============================================

Use case
--------

The main use case is that we want to offload queries from the main thread to a worker thread,
but we want to use the query result in the main thread.

Preliminary observation: The obvious solution is to make core thread safe.


Generalization
--------------

We may generalize from

a) query result -> result of any computation, as long as the result is a set of references
   to database objects residing in the same table

a2) further generalization of a) to objects in multiple tables.

b) the main versus worker thread pattern -> transfer of results between any pair of threads


Solution
--------

Recuring observation: The obvious solution is to make core thread safe :-)

Other observations

1) versioning
To handover data from one SharedGroup to another, you must take into account
the versioning of the data. Data computed from one version of the database may
not be correct when examined in the context of another version.

2) thread safety
Our SharedGroup is not thread-safe but thread specific. Accessors are part of
a datastructure rooted at SharedGroup so that they can be updated (implicitly).
To transfer a result from one SharedGroup to another, we need to add thread safe
mechanisms for unlinking the result from one SharedGroup and adding it to the other.


re Versioning

A simple way of ensuring that data transferred from one SharedGroup to another
is by ensuring that the two SharedGroups refer to the same version of data. This is
trivial, and requires adding the following
 - the ability to query a shared group which version of the database it is locked onto.
 - the ability to ask a shared group to "lock on to" a given version
 - the ability to compare versions to determine which is oldest.
This has been implemented and resides in PR #614

With this implemented *and* thread safety also implemented (which it isn't yet) we can
handover queries as long as we are careful that the queries are run in the context of
the same version of data, as the query results are later used in.

But when we want to *change* the database in accordance with a query result we get
an additional problem, because then we want to use a write transaction which by its very
nature must be the latest possible.

Important observation: this additional problem is not related to only handover, and is not
related directly to multithreading.



dead vs live table views

A live table view automatically reflect the query at all times.
A dead table reflect the query at the time it was executed.

A live table view is always valid in the sense that it always reflect
what would be the result of running its query.

A dead table view tries to remain valid even as state in the database
is changed. This allows for imperative usage, such as iterating over members
of a table view.

A live table is computationally much more expensive than a static one.

dead table views:

use case a:
  view = query(....)
  { write transaction <---- underlying table may change!
    for i in view:
      access(i)
    commit()
  }

use case b:
  view = query(.....)
  for i in view:
    { write transaction <---- underlying table may change!
      access(i)
      commit()
    }

Each new write transaction also takes in the latest commits, which may
have removed part of the objects referenced by the view.

In use case a, this happens outside of the loop and can be reflected in what
the iterator will point to during execution of the body of the loop. So this
is the easy case.

In use case b, this happens inside the loop and may cause the iterator to
refer to invalid entries, so "access(i)" should at the very least throw.
Sometimes throwing is not really what you want, so it should be possible to
ask if an iterator is ok:

use case c:
  view = query(.....)
  for i in view:
    { write transaction <---- underlying table may change!
      if (is_ok(i))
        access(i) <--- guaranteed not to throw
      commit()
    }

It would also be nice to provide an idiomatic way for handling conditional
commits:

use case d:
  view = query(.....)
  for i in view:
    if (is_ok(i) && condition_based_on_access_to(i)) { <------------ object accessed through 'i'
      { write transaction <---- underlying table may change!         must remain the same here!!
        if (is_ok(i)) <---- so i may no longer be ok                 |
          access(i) <--- guaranteed not to throw       <-------------*
        commit()
      }

More generally: If en iterator "is ok" it should point to the same object
across changes to the table, no matter if the changes are made "inside" the
current shared group or taken in during advance_read() or promote_to_write().
Also: it should be possible to advance an iterator to the next object in sort
order (or the previous) *even* if the iterator is no longer "ok".

--->> This is the same semantics as our Row objects <<----

Efficient implementation:

             ordering                   table
interator----->[   ]----table_index---->[   ]
               [   ]                    [   ]
               [   ]                    [   ]
               .....                    .....

The ordering table is identical to our existing table view.

Adding new elements to the table does not change the ordering. Removing an element
from the table does:
 - if there is an entry in the ordering with matching table_index is must be marked invalid.
 - as part of move last over, the last entry in the table changes index. If there is an entry
   in the ordering matching said entry, it must be redirected to point to the new position.
Note that we choose to mark an entry in the ordering invalid instead of deleting it.
An iterator may point to it, and marking it invalid allows for implementation of is_ok()
as well as throwing an exception on illegal access.

When the iterator is moved, invalid entries must be skipped, so movement is no longer
O(1). On the other hand, for normal use where the iterator is moved through the entire
collection one step at a time in the same direction, movement does have an amortized 
cost of O(1).

Performance:

The two linear searches needed to delete an entry are expensive: O(n). 
Binary search cannot be employed as it requires the ordering table to be ordered by 
table_index, which it isn't.

It is possible to achieve O(log(n)) using a std::map (a red-black tree) mapping from
table_index to ordering_index. This supports lookup, insertion and removal in log(n)
time. Creation of such a structure can be deferred until needed, so that we do not
pay for it unless deletion is performed. A complicating factor weighing against this
solution is that the map will require a substantial amount of memory, easily over 8
times the ordering table.


